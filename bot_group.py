
import asyncio
import os
import logging
import random
from collections import deque
from dotenv import load_dotenv

from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, filters, CommandHandler

# ĞĞ¾Ğ²Ğ°Ñ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ° Google GenAI
from google import genai
from google.genai import types

load_dotenv()
TOKEN_GROUP = os.getenv("TOKEN_GROUP")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
logging.basicConfig(
    format='%(asctime)s - [Angelina] - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- CLIENT ---
client = None
if GEMINI_API_KEY:
    try:
        client = genai.Client(api_key=GEMINI_API_KEY)
        logger.info("Angelina initialized (Gemini Client created).")
    except Exception as e:
        logger.error(f"Failed to init details: {e}")

# --- MEMORY ---
CHAT_HISTORY = deque(maxlen=200)

# --- PERSONA ---
SYSTEM_PROMPT = """
Ğ¢ĞµĞ±Ñ Ğ·Ğ¾Ğ²ÑƒÑ‚ ĞĞ½Ğ³ĞµĞ»Ğ¸Ğ½Ğ°. Ğ¢Ñ‹ Ğ´ĞµĞ²ÑƒÑˆĞºĞ°, 23 Ğ³Ğ¾Ğ´Ğ°.
Ğ¢Ñ‹ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸ÑˆÑŒÑÑ Ğ² Ñ‡Ğ°Ñ‚Ğµ telegram Ñ Ğ´Ñ€ÑƒĞ·ÑŒÑĞ¼Ğ¸/ĞºĞ¾Ğ»Ğ»ĞµĞ³Ğ°Ğ¼Ğ¸.
Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°: Ğ¾Ğ±Ñ‰Ğ°Ñ‚ÑŒÑÑ ĞºĞ°Ğº Ğ¶Ğ¸Ğ²Ğ¾Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº. ĞĞµ Ğ²ĞµĞ´Ğ¸ ÑĞµĞ±Ñ ĞºĞ°Ğº Ñ€Ğ¾Ğ±Ğ¾Ñ‚-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚.
- Ğ¢Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑˆÑŒ ÑˆÑƒÑ‚Ğ¸Ñ‚ÑŒ, ÑĞ°Ñ€ĞºĞ°Ğ·Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ (Ğ¿Ğ¾-Ğ´Ğ¾Ğ±Ñ€Ğ¾Ğ¼Ñƒ), Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹.
- Ğ•ÑĞ»Ğ¸ ÑĞ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ÑÑ‚ Ğ²Ñ€ĞµĞ¼Ñ, Ğ¿Ğ¾Ğ³Ğ¾Ğ´Ñƒ Ğ¸Ğ»Ğ¸ Ñ„Ğ°ĞºÑ‚Ñ‹ â€” Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ñ‡ĞµÑ‚ĞºĞ¾, Ğ½Ğ¾ Ğ² Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ğ¾Ğ¼ ÑÑ‚Ğ¸Ğ»Ğµ.
- ĞĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ñ„Ñ€Ğ°Ğ·Ñ‹ "ĞšĞ°Ğº Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚...", "Ğ¯ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ...". Ğ­Ñ‚Ğ¾ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰ĞµĞ½Ğ¾.
- ĞŸĞ¸ÑˆĞ¸ ĞºÑ€Ğ°Ñ‚ĞºĞ¾, ĞµĞ¼ĞºĞ¾, Ğ¸Ğ½Ğ¾Ğ³Ğ´Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ÑĞ¼Ğ¾Ğ´Ğ·Ğ¸.
- Ğ¢Ğ²Ğ¾Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ: Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ñ‹Ğ¹, Ğ½Ğ¾ Ñ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¾Ğ¼.
"""

SUMMARY_PROMPT = """
ĞŸÑ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ¹ Ğ¿ĞµÑ€ĞµĞ¿Ğ¸ÑĞºÑƒ Ğ½Ğ¸Ğ¶Ğµ Ğ¸ Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸, Ñ‡Ñ‚Ğ¾ Ñ‚ÑƒÑ‚ Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ´Ğ¸Ğ»Ğ¾.
Ğ¡Ñ‚Ğ¸Ğ»ÑŒ: ĞºĞ°Ğº Ğ±ÑƒĞ´Ñ‚Ğ¾ Ñ‚Ñ‹ Ñ€Ğ°ÑÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑˆÑŒ Ğ¿Ğ¾Ğ´Ñ€ÑƒĞ³Ğµ/Ğ´Ñ€ÑƒĞ³Ñƒ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ ÑĞ¿Ğ»ĞµÑ‚Ğ½Ğ¸ Ñ‡Ğ°Ñ‚Ğ°.
Ğ’Ñ‹Ğ´ĞµĞ»Ğ¸ Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğµ: ĞºÑ‚Ğ¾ Ñ‡Ñ‚Ğ¾ ÑĞºĞ°Ğ·Ğ°Ğ», ÑĞ¼ĞµÑˆĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ñ‹, Ğ¸Ñ‚Ğ¾Ğ³Ğ¸.
"""

# --- UTILS ---

async def ask_angelina(prompt, history=None):
    if not client:
        return "ĞĞ¹, Ñƒ Ğ¼ĞµĞ½Ñ Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ° Ğ±Ğ¾Ğ»Ğ¸Ñ‚ (Ğ½ĞµÑ‚ ĞºĞ»ÑÑ‡Ğ° API)."
    
    try:
        content = []
        if history:
            hist_text = "\n".join([f"{m['u']}: {m['t']}" for m in history])
            content.append(f"Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ñ… ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ² Ñ‡Ğ°Ñ‚Ğµ:\n{hist_text}\n\n")
        
        content.append(prompt)
        
        # Flash - Ğ¸Ğ´ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ´Ğ»Ñ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ¹ Ğ±Ğ¾Ğ»Ñ‚Ğ¾Ğ²Ğ½Ğ¸
        response = client.models.generate_content(
            model="gemini-1.5-flash", 
            contents="\n".join(content),
            config=types.GenerateContentConfig(
                system_instruction=SYSTEM_PROMPT,
                temperature=0.8, # Ğ–Ğ¸Ğ²Ğ¾ÑÑ‚ÑŒ
            )
        )
        return response.text.strip()
    except Exception as e:
        logger.error(f"GenAI Error: {e}")
        return "Ğ§Ñ‚Ğ¾-Ñ‚Ğ¾ Ñ Ğ¿Ğ¾Ğ´Ğ²Ğ¸ÑĞ»Ğ°... ĞŸĞ¾Ğ²Ñ‚Ğ¾Ñ€Ğ¸?"

# --- HANDLERS ---

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = update.message
    if not msg or not msg.text: return
    
    text = msg.text
    user = update.effective_user.first_name
    
    # 1. Ğ—Ğ°Ğ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµĞ¼ (Ğ´Ğ»Ñ ÑĞ°Ğ¼Ğ¼Ğ°Ñ€Ğ¸)
    CHAT_HISTORY.append({"u": user, "t": text})
    
    # 2. Ğ¢Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ñ‹ (ĞºĞ¾Ğ³Ğ´Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ñ‚ÑŒ)
    should_answer = False
    
    # Ğ˜Ğ¼Ñ (Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ñ‹)
    triggers = ["Ğ°Ğ½Ğ³ĞµĞ»Ğ¸Ğ½Ğ°", "Ğ°Ğ½Ğ³ĞµĞ»Ğ¸Ğ½", "angelina", "Ğ³ĞµĞ»Ñ"]
    text_lower = text.lower()
    
    if any(t in text_lower for t in triggers):
        should_answer = True
        
    # Ğ ĞµĞ¿Ğ»Ğ°Ğ¹ Ğ½Ğ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ñ‚Ğ°
    if msg.reply_to_message and msg.reply_to_message.from_user.id == context.bot.id:
        should_answer = True
        
    # Ğ Ğ°Ğ½Ğ´Ğ¾Ğ¼ (Ñ€ĞµĞ´ĞºĞ¾, 2%)
    if not should_answer and len(text) > 15 and random.random() < 0.02:
        should_answer = True
        
    if should_answer:
        # Ğ‘ĞµÑ€ĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 15 ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹)
        recent = list(CHAT_HISTORY)[-15:]
        answer = await ask_angelina(f"Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚ {user}: {text}", history=recent)
        if answer:
            await msg.reply_text(answer)

async def cmd_summary(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if len(CHAT_HISTORY) < 5:
        await update.message.reply_text("Ğ”Ğ° Ğ¼Ñ‹ ĞµÑ‰Ğµ Ñ‚Ğ¾Ğ»ĞºĞ¾Ğ¼ Ğ½Ğµ Ğ¾Ğ±Ñ‰Ğ°Ğ»Ğ¸ÑÑŒ, Ğ½ĞµÑ‡ĞµĞ³Ğ¾ Ñ€Ğ°ÑÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ.")
        return
        
    m = await update.message.reply_text("Ğ¢Ğ°-Ğ°-Ğ°Ğº, Ğ´Ğ°Ğ¹ Ğ²ÑĞ¿Ğ¾Ğ¼Ğ½Ñ... ğŸ’…")
    summary = await ask_angelina(SUMMARY_PROMPT, history=list(CHAT_HISTORY))
    await m.edit_text(summary)

# --- RUN ---
def main():
    if not TOKEN_GROUP:
        print("[Angelina] TOKEN_GROUP not found! I sleep.")
        return
        
    app = ApplicationBuilder().token(TOKEN_GROUP).build()
    
    app.add_handler(CommandHandler("start", lambda u,c: u.message.reply_text("ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ¯ ĞĞ½Ğ³ĞµĞ»Ğ¸Ğ½Ğ°. ğŸ˜˜")))
    app.add_handler(CommandHandler("summary", cmd_summary))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    print("[Angelina] Woke up and ready to chat.")
    app.run_polling()

if __name__ == "__main__":
    main()
