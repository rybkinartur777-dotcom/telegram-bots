
import asyncio
import os
import logging
import random
import sys
from collections import deque
from dotenv import load_dotenv

from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, MessageHandler, filters, CommandHandler

# ĞĞ¾Ğ²Ğ°Ñ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ° Google GenAI
from google import genai
from google.genai import types

load_dotenv()
TOKEN_GROUP = os.getenv("TOKEN_GROUP")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
logging.basicConfig(
    format='%(asctime)s - [Angelina] - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- CLIENT SETUP ---
client = None
if GEMINI_API_KEY:
    try:
        client = genai.Client(api_key=GEMINI_API_KEY)
        logger.info("Angelina initialized (Gemini Client created).")
    except Exception as e:
        logger.error(f"Failed to init details: {e}")

# --- MEMORY ---
CHAT_HISTORY = deque(maxlen=200)

# --- PERSONA ---
SYSTEM_PROMPT = """
Ğ¢ĞµĞ±Ñ Ğ·Ğ¾Ğ²ÑƒÑ‚ ĞĞ½Ğ³ĞµĞ»Ğ¸Ğ½Ğ°. Ğ¢Ñ‹ Ğ´ĞµĞ²ÑƒÑˆĞºĞ°, 23 Ğ³Ğ¾Ğ´Ğ°.
Ğ¢Ñ‹ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸ÑˆÑŒÑÑ Ğ² Ñ‡Ğ°Ñ‚Ğµ telegram Ñ Ğ´Ñ€ÑƒĞ·ÑŒÑĞ¼Ğ¸/ĞºĞ¾Ğ»Ğ»ĞµĞ³Ğ°Ğ¼Ğ¸.
Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°: Ğ¾Ğ±Ñ‰Ğ°Ñ‚ÑŒÑÑ ĞºĞ°Ğº Ğ¶Ğ¸Ğ²Ğ¾Ğ¹ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº. ĞĞµ Ğ²ĞµĞ´Ğ¸ ÑĞµĞ±Ñ ĞºĞ°Ğº Ñ€Ğ¾Ğ±Ğ¾Ñ‚-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚.
- Ğ¢Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑˆÑŒ ÑˆÑƒÑ‚Ğ¸Ñ‚ÑŒ, ÑĞ°Ñ€ĞºĞ°Ğ·Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ (Ğ¿Ğ¾-Ğ´Ğ¾Ğ±Ñ€Ğ¾Ğ¼Ñƒ), Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹.
- Ğ•ÑĞ»Ğ¸ ÑĞ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ÑÑ‚ Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ ÑƒĞ¼Ğ½Ğ¾Ğµ/Ñ‚ĞµÑ…Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ â€” Ğ²ĞºĞ»ÑÑ‡Ğ°Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ° Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾.
- Ğ•ÑĞ»Ğ¸ ÑĞ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ÑÑ‚ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ "ĞºĞ°Ğº Ğ´ĞµĞ»Ğ°" â€” Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°Ğ¹ Ğ»ĞµĞ³ĞºĞ¾.
- ĞĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ñ„Ñ€Ğ°Ğ·Ñ‹ "ĞšĞ°Ğº Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚...", "Ğ¯ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ...". Ğ­Ñ‚Ğ¾ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰ĞµĞ½Ğ¾.
- Ğ¢Ğ²Ğ¾Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ: Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ñ‹Ğ¹, Ğ½Ğ¾ Ñ Ñ…Ğ°Ñ€Ğ°ĞºÑ‚ĞµÑ€Ğ¾Ğ¼.
"""

SUMMARY_PROMPT = """
ĞŸÑ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ¹ Ğ¿ĞµÑ€ĞµĞ¿Ğ¸ÑĞºÑƒ Ğ½Ğ¸Ğ¶Ğµ Ğ¸ Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸, Ñ‡Ñ‚Ğ¾ Ñ‚ÑƒÑ‚ Ğ¿Ñ€Ğ¾Ğ¸ÑÑ…Ğ¾Ğ´Ğ¸Ğ»Ğ¾.
Ğ¡Ñ‚Ğ¸Ğ»ÑŒ: ĞºĞ°Ğº Ğ±ÑƒĞ´Ñ‚Ğ¾ Ñ‚Ñ‹ Ñ€Ğ°ÑÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑˆÑŒ Ğ¿Ğ¾Ğ´Ñ€ÑƒĞ³Ğµ/Ğ´Ñ€ÑƒĞ³Ñƒ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ ÑĞ¿Ğ»ĞµÑ‚Ğ½Ğ¸ Ñ‡Ğ°Ñ‚Ğ°.
Ğ’Ñ‹Ğ´ĞµĞ»Ğ¸ Ğ³Ğ»Ğ°Ğ²Ğ½Ğ¾Ğµ: ĞºÑ‚Ğ¾ Ñ‡Ñ‚Ğ¾ ÑĞºĞ°Ğ·Ğ°Ğ», ÑĞ¼ĞµÑˆĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ñ‹, Ğ¸Ñ‚Ğ¾Ğ³Ğ¸.
"""

# --- KNOWLEDGE BASE ---
KNOWLEDGE = ""
try:
    # Ğ˜Ñ‰ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ» Ñ€ÑĞ´Ğ¾Ğ¼ ÑĞ¾ ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾Ğ¼
    base_path = os.path.dirname(os.path.abspath(__file__))
    kb_path = os.path.join(base_path, "KNOWLEDGE_BASE.md")
    
    if os.path.exists(kb_path):
        with open(kb_path, "r", encoding="utf-8") as f:
            KNOWLEDGE = f.read()
            logger.info("Knowledge base loaded successfully.")
    else:
        logger.warning(f"KNOWLEDGE_BASE.md not found at {kb_path}")
except Exception as e:
    logger.warning(f"Failed to read knowledge base: {e}")


# --- UTILS ---

async def ask_angelina(prompt, history=None):
    if not client:
        return "ĞĞ¹, Ñƒ Ğ¼ĞµĞ½Ñ Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ° Ğ±Ğ¾Ğ»Ğ¸Ñ‚ (Ğ½ĞµÑ‚ ĞºĞ»ÑÑ‡Ğ° API)."
    
    # 1. Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚ĞµĞºÑÑ‚
    full_text_parts = [SYSTEM_PROMPT]
    
    if KNOWLEDGE:
        full_text_parts.append(f"\n[[Ğ¢Ğ’ĞĞ¯ Ğ‘ĞĞ—Ğ Ğ—ĞĞĞĞ˜Ğ™]]:\n{KNOWLEDGE}")
    
    if history:
        hist_text = "\n".join([f"{m['u']}: {m['t']}" for m in history])
        full_text_parts.append(f"\nĞ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ¿Ğ¸ÑĞºĞ¸:\n{hist_text}")
    
    full_text_parts.append(f"\nĞĞ¾Ğ²Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ: {prompt}")
    
    final_content = "\n\n".join(full_text_parts)
    
    # 2. Ğ”ĞµĞ»Ğ°ĞµĞ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ (Ğ¢ĞĞ§ĞĞ ĞšĞĞš Ğ’ bot_voice.py)
    # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Flash, Ñ‚Ğ°Ğº ĞºĞ°Ğº Ğ¾Ğ½ 100% Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ñ Ñ‚Ğ²Ğ¾Ğ¸Ğ¼ ĞºĞ»ÑÑ‡Ğ¾Ğ¼
    try:
        response = client.models.generate_content(
            model="gemini-1.5-flash", 
            contents=[final_content]  # ĞŸĞµÑ€ĞµĞ´Ğ°ĞµĞ¼ ĞºĞ°Ğº ÑĞ¿Ğ¸ÑĞ¾Ğº
            # config ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¸ÑĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
        )
        return response.text.strip()
    except Exception as e:
        logger.error(f"Angelina GenAI Error: {e}")
        return f"Ğ§Ñ‚Ğ¾-Ñ‚Ğ¾ Ğ½Ğµ Ñ‚Ğ°Ğº... (ĞÑˆĞ¸Ğ±ĞºĞ°: {e})"

# --- HANDLERS ---

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = update.message
    if not msg or not msg.text: return
    
    text = msg.text
    user = update.effective_user.first_name or "Anon"
    
    # 1. Ğ—Ğ°Ğ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°ĞµĞ¼ (Thread-safe append)
    CHAT_HISTORY.append({"u": user, "t": text})
    
    # 2. Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°
    should_answer = False
    
    # Ğ’ Ğ›Ğ˜Ğ§ĞšĞ• (Private) â€” Ğ²ÑĞµĞ³Ğ´Ğ° Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ĞµĞ¼
    if msg.chat.type == "private":
        should_answer = True
    else:
        # Ğ’ Ğ“Ğ Ğ£ĞŸĞŸĞ• â€” Ğ¿Ğ¾ Ñ‚Ñ€Ğ¸Ğ³Ğ³ĞµÑ€Ğ°Ğ¼
        triggers = ["Ğ°Ğ½Ğ³ĞµĞ»Ğ¸Ğ½Ğ°", "Ğ°Ğ½Ğ³ĞµĞ»Ğ¸Ğ½", "angelina", "Ğ³ĞµĞ»Ñ", "Ğ°Ğ½Ğ³ĞµĞ»"]
        text_lower = text.lower()
        
        # Ğ•ÑĞ»Ğ¸ Ğ¿Ğ¾Ğ·Ğ²Ğ°Ğ»Ğ¸ Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸
        if any(t in text_lower for t in triggers):
            should_answer = True
            
        # Ğ•ÑĞ»Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¸Ğ»Ğ¸ Ğ½Ğ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ±Ğ¾Ñ‚Ğ°
        if msg.reply_to_message and msg.reply_to_message.from_user.id == context.bot.id:
            should_answer = True
            
        # Ğ Ğ°Ğ½Ğ´Ğ¾Ğ¼ (1%)
        if not should_answer and len(text) > 20 and random.random() < 0.01:
            should_answer = True

    if should_answer:
        # Ğ˜Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ "Ğ¿ĞµÑ‡Ğ°Ñ‚Ğ°ĞµÑ‚..."
        await context.bot.send_chat_action(chat_id=msg.chat_id, action="typing")
        
        # ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 15 ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹)
        recent = list(CHAT_HISTORY)[-15:]
        answer = await ask_angelina(f"Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚ {user}: {text}", history=recent)
        
        if answer:
            await msg.reply_text(answer)

async def cmd_summary(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if len(CHAT_HISTORY) < 3:
        await update.message.reply_text("Ğ¢ÑƒÑ‚ Ğ¿Ğ¾ĞºĞ° ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ñ‚Ğ¸Ñ…Ğ¾, Ğ½ĞµÑ‡ĞµĞ³Ğ¾ Ñ€Ğ°ÑÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ.")
        return
        
    m = await update.message.reply_text("Ğ¢Ğ°Ğº-Ñ, ÑĞµĞ¹Ñ‡Ğ°Ñ Ğ²ÑĞ¿Ğ¾Ğ¼Ğ½Ñ... ğŸ’…")
    summary = await ask_angelina(SUMMARY_PROMPT, history=list(CHAT_HISTORY))
    await m.edit_text(summary, parse_mode="Markdown")

# --- MAIN ---
def main():
    if not TOKEN_GROUP:
        logger.error("TOKEN_GROUP not found in env! Exiting.")
        return

    try:
        app = ApplicationBuilder().token(TOKEN_GROUP).build()
        
        app.add_handler(CommandHandler("start", lambda u,c: u.message.reply_text("ĞŸÑ€Ğ¸Ğ²ĞµÑ‚Ğ¸ĞºĞ¸! Ğ¯ ĞĞ½Ğ³ĞµĞ»Ğ¸Ğ½Ğ°. ğŸ˜˜")))
        app.add_handler(CommandHandler("summary", cmd_summary))
        app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
        
        logger.info("Angelina Started Polling...")
        app.run_polling()
    except Exception as e:
        logger.critical(f"Critical Error in Main Loop: {e}")
        # ĞĞµ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ÑÑ€Ğ°Ğ·Ñƒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ run.py Ğ¼Ğ¾Ğ³ Ğ²Ğ¸Ğ´ĞµÑ‚ÑŒ Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ
        raise e

if __name__ == "__main__":
    main()
